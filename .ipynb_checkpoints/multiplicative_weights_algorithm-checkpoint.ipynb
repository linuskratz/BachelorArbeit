{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df6ac98",
   "metadata": {},
   "source": [
    "# MULTIPLICATIVE WEIGHTS ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf984a1",
   "metadata": {},
   "source": [
    "## DESCRIPTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5f8fbf0",
   "metadata": {},
   "source": [
    " this implementation of the multicative weights algorithm works for NxM, 2 player games \n",
    " a game input should contain the payoffs for each player given a pair of strategies\n",
    " a game is a list; the game contains a list for each strategy of player 0, \n",
    " each list of a player 0 strategy contains a list of all player 1 strategies\n",
    " for each strategy_p0, strategy_p1 pair we include the below payoff\n",
    " a payoff looks like [player_0_payoff, player_1_payoff]\n",
    " \n",
    " Based on http://web.stanford.edu/~rjohari/teaching/notes/336_lecture11_2007.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ad776",
   "metadata": {},
   "source": [
    "## EXAMPLE GAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e383826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matching_pennies = [[[1.0,-1.0], [-1.0, 1.0]], \n",
    "                    [[-1.0, 1.0], [1.0,-1.0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbee875",
   "metadata": {},
   "source": [
    "## ALGORITHM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "316402cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e9bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# input: a strategy in the form of \n",
    "# example_input: strategy = [[0.2, 0.8], [0.3, 0.7]] for 2x2 , 2 player game \n",
    "\n",
    "def calculate_joint_strategy(strategy):\n",
    "    p0_strategy = np.transpose([strategy[0]])\n",
    "    p1_strategy =[strategy[1]]\n",
    "    joint_strategy_profile = np.matmul(p0_strategy, p1_strategy)\n",
    "    return joint_strategy_profile             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d718b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a 2x2, 2 player game\n",
    "# example: joint strategy profile is of the form: [[0.06, 0.14], [0.24, 0.56]] \n",
    "def calculate_joint_payoff(game, joint_strategy_profile):\n",
    "    return np.transpose(np.transpose(game) * np.transpose(joint_strategy_profile))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e65e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_no's payoff from a joint_payoff_vector \n",
    "# for a 2x2, 2 player game, example joint_payoff for matching pennis: \n",
    "# [[[0.06, -0.06], [-0.14, 0.14]], [[-0.24, 0.24], [0.56, -0.56]]]\n",
    "def calculate_player_payoff(player_no, joint_payoff): \n",
    "    return sum(sum(joint_payoff))[player_no]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "387e8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_of_actions (game, player_no): \n",
    "    return np.array(game).shape[player_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f77bfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the strategy profile of both players \n",
    "# both players play each option with 1/no_actions\n",
    "def initial_history_disc_uni_dist(game): \n",
    "    no_of_actions_p0 = no_of_actions (game, 0)\n",
    "    no_of_actions_p1 = no_of_actions (game, 1)\n",
    "    history = [([1/no_of_actions_p0] * no_of_actions_p0), ([1/no_of_actions_p1] * no_of_actions_p1)]\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a3993ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_history_random_distribution(game): \n",
    "    no_of_actions_p0 = no_of_actions (game, 0)\n",
    "    no_of_actions_p1 = no_of_actions (game, 1)\n",
    "    random_dist_p0 = np.random.random_sample(no_of_actions_p0)\n",
    "    random_dist_p1 = np.random.random_sample(no_of_actions_p1)\n",
    "    #normalize \n",
    "    random_dist_p0 = random_dist_p0 / sum(random_dist_p0)\n",
    "    random_dist_p1 = random_dist_p1 / sum(random_dist_p1)\n",
    "    \n",
    "    return [random_dist_p0.tolist(), random_dist_p1.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b349d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function calculates the payoff of playing action_no by player_no with 1.0 \n",
    "# given past_other_player_strategies\n",
    "def calculate_alternate_player_payoff(game, player_no, action_no, past_other_player_strategy): \n",
    "    number_of_actions = no_of_actions(game, player_no)\n",
    "    action_profile = [0.0] * number_of_actions\n",
    "    action_profile[action_no] = 1.0\n",
    "    strategy_profile = [past_other_player_strategy]\n",
    "    strategy_profile.insert(player_no, action_profile)\n",
    "    joint_strategy_profile = calculate_joint_strategy(strategy_profile)    \n",
    "    joint_payoff = calculate_joint_payoff (game, joint_strategy_profile)\n",
    "    return calculate_player_payoff(player_no, joint_payoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c609962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_beta_update(game, player_no, action_no, beta, history): \n",
    "    last_played_prob = history[player_no][action_no]\n",
    "    other_player_last_played_prob = history[(1-player_no)]\n",
    "    alternate_action_payoff = calculate_alternate_player_payoff(game, player_no, action_no, other_player_last_played_prob)\n",
    "    result = last_played_prob * beta**-alternate_action_payoff\n",
    "    return result \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f44c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_next_step(game, player_no, action_no, beta, history): \n",
    "    numerator = history_beta_update(game, player_no, action_no, beta, history)\n",
    "    number_of_actions = no_of_actions(game, player_no)\n",
    "    denominator = 0.0\n",
    "    for other_action in range(number_of_actions): \n",
    "        if other_action == action_no: \n",
    "            denominator += numerator\n",
    "        else: \n",
    "            denominator += history_beta_update(game, player_no, other_action, beta, history)\n",
    "    return numerator / denominator \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c7e2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(history, new_history): \n",
    "    # as history.p0.shape sometimes != history.p1.shape\n",
    "    p0_hist = np.array(history[0])\n",
    "    p1_hist = np.array(history[1])\n",
    "    \n",
    "    p0_new_hist = np.array(new_history[0])\n",
    "    p1_new_hist = np.array(new_history[1])    \n",
    "    \n",
    "    p0_distance = (p0_hist - p0_new_hist)**2\n",
    "    p1_distance = (p1_hist - p1_new_hist)**2\n",
    "    distance = sum(p0_distance) + sum(p1_distance)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "254ed371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_mean = old_mean + (new_value - old_mean) / step\n",
    "# https://math.stackexchange.com/questions/106700/incremental-averaging\n",
    "def update_mean_history(mean_history, update_history, step): \n",
    "    p0_distribution = np.array(mean_history[0])  \n",
    "    p1_distribution = np.array(mean_history[1]) \n",
    "    new_p0_mean = p0_distribution + (np.array(update_history[0]) - p0_distribution)/step\n",
    "    new_p1_mean = p1_distribution + (np.array(update_history[1]) - p1_distribution)/step\n",
    "    return [new_p0_mean.tolist(), new_p1_mean.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bef44600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_distribution(probabilities):\n",
    "    return random.choices(range(0,len(probabilities)), weights = probabilities)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ddaa027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init history is a mixed strategy for both players\n",
    "def multiplicative_weights(game, epsilon, beta, init_history, max_steps): \n",
    "    mean_histories = [init_history]\n",
    "    mean_history = init_history\n",
    "    current_history = init_history\n",
    "    no_of_actions_p1 = no_of_actions (game, 0)\n",
    "    no_of_actions_p2 = no_of_actions (game, 1)\n",
    "    iters = 1\n",
    "    histories = [init_history]\n",
    "    while 1: \n",
    "        p1_strategy = [calculate_next_step(game, 0, i, beta, current_history) for i in range(no_of_actions_p1)]\n",
    "        p2_strategy = [calculate_next_step(game, 1, i, beta, current_history) for i in range(no_of_actions_p2)]\n",
    "        new_history = [p1_strategy, p2_strategy]\n",
    "        iters +=1\n",
    "        new_mean_history = update_mean_history(mean_history, new_history, iters)\n",
    "        mean_histories.append(new_mean_history)\n",
    "        histories.append(new_history)\n",
    "        # check if multiplicative weights has converged or doesnt converge\n",
    "        if  (euclidean_distance (new_mean_history, mean_history) <= epsilon) or iters == max_steps: \n",
    "            break\n",
    "        current_history = new_history\n",
    "        mean_history = new_mean_history\n",
    "    return mean_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80ffb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the history of strategy profiles for player\n",
    "def get_history(player_no, history): \n",
    "    return [strategy[player_no] for strategy in history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ffabbc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, game_name): \n",
    "   \n",
    "    \n",
    "    hist_p0 = np.transpose(get_history(0, history))\n",
    "    hist_p1 = np.transpose(get_history(1, history))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for action_no, action_history_p0 in enumerate(hist_p0):\n",
    "        ax.plot(range(len(action_history_p0)), action_history_p0, label =\"player:0, action:{}\".format(action_no))\n",
    "    \n",
    "    for action_no, action_history_p1 in enumerate(hist_p1):\n",
    "        ax.plot(range(len(action_history_p1)), action_history_p1, label =\"player:1, action:{}\".format(action_no))\n",
    "    \n",
    "    ax.set_title(\"Multiplicative weights algorithm with {}\".format(game_name))\n",
    "    ax.set_xlabel('Number of iterations')\n",
    "    ax.set_ylabel('Strategy probability')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de8e0183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplicative_weights_plot(game, game_name, init_history, beta = 0.7, epsilon = 0.00001, max_steps = 100000): \n",
    "    mean_history = multiplicative_weights(game, epsilon, beta, init_history, max_steps)\n",
    "    #plot_history(history, game_name)\n",
    "    #print(np.mean(np.transpose(history), axis = 2))\n",
    "    plot_history(mean_history, game_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c59024",
   "metadata": {},
   "source": [
    "# FINDINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86d6c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiplicative_weights_plot(matching_pennies, \"matching_pennies\", initial_history_random_distribution(matching_pennies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d3ed7de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#multiplicative_weights_plot(schere_strein_papier, \"schere_strein_papier\", initial_history_random_distribution(schere_strein_papier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "834ba126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiplicative_weights_plot(prisoners_dilemma,\"prisoners_dilemma\", initial_history_random_distribution(prisoners_dilemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcab920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiplicative_weights_plot(test_game_2, \"test_game_2\", initial_history_disc_uni_dist(test_game_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97079615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiplicative_weights_plot(shapley_game, \"shapley_game\", initial_history_random_distribution(shapley_game))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
